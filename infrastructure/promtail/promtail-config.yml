# Promtail Configuration
# Collects logs from Docker containers and forwards to Loki

server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: info

positions:
  filename: /tmp/positions/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push
    timeout: 10s
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10
    batchwait: 1s
    batchsize: 102400  # 100KB

scrape_configs:
  # Docker container logs via Docker API
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ["com.docker.compose.project=north-cloud"]

    relabel_configs:
      # Extract container name (remove leading slash and project prefix)
      - source_labels: ['__meta_docker_container_name']
        regex: '/north-cloud-(.+?)(?:-\d+)?'
        target_label: 'service'
        replacement: '${1}'

      # Extract service name from Docker Compose label (more reliable)
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: 'service'

      # Extract project name
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: 'project'

      # Add static project label if not present
      - target_label: 'project'
        replacement: 'north-cloud'
        action: replace
        source_labels: []

      # Extract container ID (short version, first 12 chars)
      - source_labels: ['__meta_docker_container_id']
        regex: '^(.{12}).*'
        target_label: 'container_id'

      # Add job label
      - target_label: 'job'
        replacement: 'docker'

    pipeline_stages:
      # Parse JSON logs from Docker (Docker wraps logs in JSON with 'log', 'stream', 'time' fields)
      - json:
          expressions:
            log: log
            stream: stream
            time: time

      # Parse the actual log line as JSON (all services now use JSON format)
      - json:
          expressions:
            level: level
            logger: logger
            caller: caller
            msg: msg
            ts: ts
            service: service
            method: method
            error: error
            duration: duration
            status_code: status_code
          source: log

      # Extract level label from JSON (primary source)
      # This extracts the 'level' field from the parsed JSON and adds it as a label
      - labels:
          level:

      # If JSON parsing succeeded, use the parsed timestamp (more accurate than Docker's time)
      - timestamp:
          source: ts
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - "2006-01-02T15:04:05.000Z07:00"
            - "2006-01-02T15:04:05Z07:00"
          on_failure: drop

      # Fallback to Docker's timestamp if JSON timestamp parsing failed
      - timestamp:
          source: time
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - "2006-01-02T15:04:05.000Z07:00"
            - "2006-01-02T15:04:05Z07:00"
          on_failure: drop

      # Add stream label (stdout/stderr)
      - labels:
          stream:

      # If service was extracted from log JSON, use it; otherwise keep the label from relabel_configs
      - labels:
          service:

      # Output formatting - use msg if available (from JSON), otherwise use log (raw)
      - output:
          source: msg
          on_failure: log

  # Nginx access logs (if mounted)
  - job_name: nginx_access
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          log_type: access
          __path__: /var/log/nginx/access.log

    pipeline_stages:
      # Parse nginx access log format
      - regex:
          expression: '^(?P<remote_addr>[\w\.]+) - (?P<remote_user>[\w-]+) \[(?P<time_local>.*?)\] "(?P<method>\w+) (?P<request>.*?) (?P<protocol>HTTP/[\d\.]+)" (?P<status>\d+) (?P<body_bytes_sent>\d+) "(?P<http_referer>.*?)" "(?P<http_user_agent>.*?)"'

      - timestamp:
          source: time_local
          format: "02/Jan/2006:15:04:05 -0700"

      - labels:
          method:
          status:

      - static_labels:
          service: nginx
          level: info

  # Nginx error logs (if mounted)
  - job_name: nginx_error
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          log_type: error
          __path__: /var/log/nginx/error.log

    pipeline_stages:
      # Parse nginx error log format
      - regex:
          expression: '^(?P<timestamp>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?P<level>\w+)\] (?P<message>.*)'

      - timestamp:
          source: timestamp
          format: "2006/01/02 15:04:05"

      - labels:
          level:

      - static_labels:
          service: nginx

limits_config:
  readline_rate_enabled: false
  readline_rate: 10000
  readline_burst: 20000
