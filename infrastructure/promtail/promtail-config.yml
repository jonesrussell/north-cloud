# Promtail Configuration
# Collects logs from Docker containers and forwards to Loki

server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: info

positions:
  filename: /tmp/positions/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push
    timeout: 10s
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10
    batchwait: 1s
    batchsize: 102400  # 100KB

scrape_configs:
  # Docker container logs via file system (avoids Docker API version issues)
  - job_name: docker
    static_configs:
      - targets:
          - localhost
        labels:
          job: docker
          __path__: /var/lib/docker/containers/*/*-json.log

    pipeline_stages:
      # Extract container ID from file path
      - regex:
          expression: '/var/lib/docker/containers/(?P<container_id>[^/]+)/.*'
          source: filename

      # Parse JSON logs from Docker (Docker wraps logs in JSON with 'log', 'stream', 'time' fields)
      - json:
          expressions:
            log: log
            stream: stream
            time: time

      # Extract timestamp from Docker's 'time' field
      - timestamp:
          source: time
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - "2006-01-02T15:04:05.000Z07:00"
            - "2006-01-02T15:04:05Z07:00"

      # Try to parse the actual log line as JSON (for structured logs from Go services)
      - json:
          expressions:
            level: level
            logger: logger
            caller: caller
            msg: msg
            ts: ts
            service_name: service
            method: method
            error: error
            duration: duration
            status_code: status_code
          source: log
          drop_malformed: true

      # If JSON parsing succeeded, use the parsed timestamp
      - timestamp:
          source: ts
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - "2006-01-02T15:04:05.000Z07:00"
            - "2006-01-02T15:04:05Z07:00"
          on_failure: drop

      # Add log level as a label for easy filtering
      - labels:
          level:
          service_name:
          stream:

      # Add container ID label (short version, first 12 chars)
      - labels:
          container_id:
      - regex:
          expression: '^(.{12}).*'
          source: container_id
          target_label: container_id_short

      # Add static labels
      - static_labels:
          job: docker

      # Output formatting
      - output:
          source: msg
          on_failure: log

  # Nginx access logs (if mounted)
  - job_name: nginx_access
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          log_type: access
          __path__: /var/log/nginx/access.log

    pipeline_stages:
      # Parse nginx access log format
      - regex:
          expression: '^(?P<remote_addr>[\w\.]+) - (?P<remote_user>[\w-]+) \[(?P<time_local>.*?)\] "(?P<method>\w+) (?P<request>.*?) (?P<protocol>HTTP/[\d\.]+)" (?P<status>\d+) (?P<body_bytes_sent>\d+) "(?P<http_referer>.*?)" "(?P<http_user_agent>.*?)"'

      - timestamp:
          source: time_local
          format: "02/Jan/2006:15:04:05 -0700"

      - labels:
          method:
          status:

      - static_labels:
          service: nginx
          level: info

  # Nginx error logs (if mounted)
  - job_name: nginx_error
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          log_type: error
          __path__: /var/log/nginx/error.log

    pipeline_stages:
      # Parse nginx error log format
      - regex:
          expression: '^(?P<timestamp>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?P<level>\w+)\] (?P<message>.*)'

      - timestamp:
          source: timestamp
          format: "2006/01/02 15:04:05"

      - labels:
          level:

      - static_labels:
          service: nginx

limits_config:
  readline_rate_enabled: false
  readline_rate: 10000
  readline_burst: 20000
